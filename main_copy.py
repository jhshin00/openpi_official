#!/usr/bin/env python3
"""
UR3 Robot Control Script using Gello Teleoperator + OpenPI Client
í›ˆë ¨ëœ UR3 policyë¥¼ ì‹¤ì œ ë¡œë´‡ì— ì ìš©í•˜ëŠ” script
gello í™˜ê²½ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì…ë ¥ê³¼ ë¡œë´‡ ìƒíƒœë¥¼ ë°›ì•„ì„œ policy inference í›„ ë¡œë´‡ ì œì–´
"""

import datetime
import glob
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Tuple, List, Dict, Any

import threading

import numpy as np
import tyro
import h5py
import cv2
import pyrealsense2 as rs

# Gello ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    from gello.agents.agent import DummyAgent
    from gello.agents.gello_agent import GelloAgent
    from gello.env import RobotEnv
    from gello.robots.robot import PrintRobot
    from gello.zmq_core.robot_node import ZMQClientRobot
    from gello.zmq_core.camera_node import ZMQClientCamera, ZMQServerCamera
    from gello.cameras.camera import CameraDriver
    GELLO_AVAILABLE = True
except ImportError:
    print("âš ï¸  Warning: Gello libraries not found. Install them for robot control.")
    GELLO_AVAILABLE = False

# OpenPI Client
try:
    from openpi_client import websocket_client_policy as _websocket_client_policy
    OPENPI_AVAILABLE = True
except ImportError:
    print("âš ï¸  Warning: OpenPI client not found. Install it with: pip install openpi_client")
    OPENPI_AVAILABLE = False

def print_color(*args, color=None, attrs=(), **kwargs):
    import termcolor

    if len(args) > 0:
        args = tuple(termcolor.colored(arg, color=color, attrs=attrs) for arg in args)
    print(*args, **kwargs)


@dataclass
class Args:
    # Policy server configuration
    policy_host: str = "localhost"
    policy_port: int = 8000
    api_key: Optional[str] = None
    
    # Task configuration
    task_prompt: str = "pick up the green grape and put it in the gray pot"
    
    # Robot configuration
    robot_port: int = 6001
    wrist_camera_port: int = 5000
    base_camera_port: int = 5001
    hostname: str = "127.0.0.1"
    hz: int = 40  # UR3 ì œì–´ ì£¼íŒŒìˆ˜ (ë” ë†’ì€ ì£¼íŒŒìˆ˜ë¡œ ë¶€ë“œëŸ¬ìš´ ì›€ì§ì„)
    
    # Agent configuration
    agent: str = "policy"  # "none", "gello", "policy"
    gello_port: Optional[str] = None
    start_joints: Optional[Tuple[float, ...]] = None
    
    # Camera configuration
    camera_width: int = 640
    camera_height: int = 480
    camera_fps: int = 30
    
    # Control parameters
    max_joint_delta: float = 0.8
    open_loop_horizon: int = 5  # ëª‡ ê°œì˜ actionì„ ì‹¤í–‰í•œ í›„ ìƒˆë¡œìš´ chunk ìš”ì²­í• ì§€
    smoothing_factor: float = 0.3  # Action smoothing factor (0.1~0.5, ë‚®ì„ìˆ˜ë¡ ë¶€ë“œëŸ¬ì›€)
    max_action_velocity: float = 0.1  # ìµœëŒ€ action velocity ì œí•œ
    interpolation_steps: int = 3  # Action ê°„ ë³´ê°„ ë‹¨ê³„ ìˆ˜ (ë†’ì„ìˆ˜ë¡ ë¶€ë“œëŸ¬ì›€)
    
    # Data saving
    use_save_interface: bool = True
    data_dir: str = "~/ur3_data"
    
    # Mock mode
    mock: bool = False


class RealSenseDriver(CameraDriver):
    def __init__(self, serial: str, width=640, height=480, fps=30):
        self.serial = serial
        self.pipeline = rs.pipeline()
        cfg = rs.config()
        cfg.enable_device(serial)
        cfg.enable_stream(rs.stream.color, width, height, rs.format.bgr8, fps)
        self.pipeline.start(cfg)

    def read(self, img_size=None):
        frames = self.pipeline.wait_for_frames()
        color = frames.get_color_frame()
        img = np.asanyarray(color.get_data())
        if img_size is not None:
            img = cv2.resize(img, (img_size[1], img_size[0]))
        return img

    def __str__(self):
        return f"RealSense({self.serial})"

    def close(self):
        try:
            self.pipeline.stop()
        except Exception:
            pass

    def __del__(self):
        self.close()


def start_server(port, driver):
    server = ZMQServerCamera(driver, port=port)
    server.serve()


class AsyncCamera:
    def __init__(self, client: ZMQClientCamera, target_size=(224, 224), crop_center=None):
        self.client = client
        self.target_size = target_size
        h, w = 320, 320
        self.frame = None
        self.lock = threading.Lock()

        self.crop_center = crop_center

        if crop_center is not None:
            cy, cx = crop_center
            self.x1 = max(cx - w // 2, 0)
            self.x2 = min(cx + w // 2, 640)
            self.y1 = max(cy - h // 2, 0)
            self.y2 = min(cy + h // 2, 480)
        else:
            self.x1 = self.x2 = self.y1 = self.y2 = None

        # ë°ëª¬ ì“°ë ˆë“œë¡œ ë°±ê·¸ë¼ìš´ë“œì—ì„œ í”„ë ˆì„ ê°±ì‹ 
        t = threading.Thread(target=self._update_loop, daemon=True)
        t.start()

    def _update_loop(self):
        while True:
            try:
                raw = self.client.read()
                if raw is None:
                    time.sleep(0.002)
                    continue
                if self.crop_center is not None:
                    crop = raw[self.y1:self.y2, self.x1:self.x2]
                    img = cv2.resize(crop, self.target_size, interpolation=cv2.INTER_LINEAR)
                else:
                    img = cv2.resize(raw, self.target_size, interpolation=cv2.INTER_LINEAR)

                with self.lock:
                    self.frame = img
            except Exception as e:
                time.sleep(0.01)

    def read(self):
        # ìµœì´ˆ í”„ë ˆì„ ì—†ìœ¼ë©´ ì ê¹ ëŒ€ê¸°
        if self.frame is None:
            for _ in range(50):
                time.sleep(0.005)
                if self.frame is not None:
                    break
        with self.lock:
            return None if self.frame is None else self.frame.copy()


class PolicyAgent:
    """OpenPI Policyë¥¼ ì‚¬ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ - Smooth Action Interpolation"""
    
    def __init__(self, host: str, port: int, api_key: Optional[str] = None, task_prompt: str = "pick up the green grape and put it in the gray pot", open_loop_horizon: int = 5):
        if not OPENPI_AVAILABLE:
            raise ImportError("OpenPI client not available")
        
        self.policy = _websocket_client_policy.WebsocketClientPolicy(
            host=host,
            port=port,
            api_key=api_key,
        )
        
        # ğŸ¯ Task prompt ê²€ì¦ ë° ì •ë¦¬
        if not task_prompt or len(task_prompt.strip()) == 0:
            raise ValueError("Task prompt cannot be empty!")
        
        self.task_prompt = task_prompt.strip()
        self.open_loop_horizon = open_loop_horizon
        
        # Simple action buffer
        self.action_buffer = None
        self.action_idx = 0
        
        # Action Smoothingì„ ìœ„í•œ ìƒíƒœ
        self.last_smoothed_action = None
        self.smoothing_factor = 0.3  # ë‚®ì„ìˆ˜ë¡ ë¶€ë“œëŸ¬ì›€ (0.1~0.5)
        self.max_velocity = 0.1  # ìµœëŒ€ joint velocity ì œí•œ
        
        # ğŸ¯ Action Interpolationì„ ìœ„í•œ ìƒíƒœ
        self.interpolation_steps = 3  # action ê°„ ë³´ê°„ ë‹¨ê³„ ìˆ˜
        self.interpolation_counter = 0  # í˜„ì¬ ë³´ê°„ ë‹¨ê³„
        self.current_action = None  # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ action
        self.next_action = None  # ë‹¤ìŒ action
        
        print(f"âœ… Policy server connected to {host}:{port}")
        print(f"ğŸ“ Task: '{self.task_prompt}'")
        print(f"ğŸ”„ Short horizon: {self.open_loop_horizon} actions")
        print(f"ğŸš€ Smooth Action Interpolation + Smoothing mode enabled")
        print(f"ğŸ”„ Smoothing factor: {self.smoothing_factor}")
        print(f"ğŸ”„ Max velocity: {self.max_velocity}")
        print(f"ğŸ”„ Interpolation steps: {self.interpolation_steps}")
        
        # ì„œë²„ ë©”íƒ€ë°ì´í„° í™•ì¸
        try:
            metadata = self.policy.get_server_metadata()
            print(f"ğŸ“‹ Server metadata: {metadata}")
            
            # ğŸš¨ Policy ì„œë²„ê°€ task promptë¥¼ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸
            if hasattr(metadata, 'get') and metadata.get('supports_task_prompt', False):
                print("âœ… Policy server supports task prompts")
            else:
                print("âš ï¸  Policy server may not support task prompts")
                
        except Exception as e:
            print(f"âš ï¸  Could not get server metadata: {e}")
    
    def act(self, obs: dict) -> np.ndarray:
        """Smooth Action Interpolation ë°©ì‹ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ action ì œê³µ"""
        try:
            current_joints = obs["joint_positions"]
            
            # Action bufferê°€ ë¹„ì–´ìˆê±°ë‚˜ ì™„ë£Œë˜ë©´ ìƒˆë¡œìš´ action ìš”ì²­
            if self.action_buffer is None or self.action_idx >= len(self.action_buffer):
                print(f"\nğŸ”„ Requesting new actions (horizon: {self.open_loop_horizon})")
                self._request_new_actions(obs)
                
                if self.action_buffer is None:
                    return np.array(current_joints, dtype=np.float32)
                
                # ìƒˆë¡œìš´ action buffer ì‹œì‘ ì‹œ ì´ˆê¸°í™”
                self.interpolation_counter = 0
                self.current_action = current_joints.copy()
                self.next_action = np.array(self.action_buffer[0], dtype=np.float32)
            
            # ğŸ¯ Action Interpolation ì ìš©
            if self.interpolation_counter < self.interpolation_steps:
                # ë³´ê°„ ë‹¨ê³„ ì‹¤í–‰
                interpolated_action = self._interpolate_action(
                    self.current_action, 
                    self.next_action, 
                    self.interpolation_counter, 
                    self.interpolation_steps
                )
                
                self.interpolation_counter += 1
                
                # Action Smoothing ì ìš©
                smoothed_action = self._smooth_action(interpolated_action, current_joints)
                
                # Velocity ì œí•œ ì ìš©
                final_action = self._limit_velocity(smoothed_action, current_joints)
                
                print(f"  ğŸ¯ Interpolation step {self.interpolation_counter}/{self.interpolation_steps}: {final_action[:3]}...")
                return final_action
            
            else:
                # ë³´ê°„ ì™„ë£Œ, ë‹¤ìŒ actionìœ¼ë¡œ ì§„í–‰
                self.action_idx += 1
                self.interpolation_counter = 0
                
                if self.action_idx < len(self.action_buffer):
                    # ë‹¤ìŒ actionìœ¼ë¡œ ë³´ê°„ ì‹œì‘
                    self.current_action = self.next_action.copy()
                    self.next_action = np.array(self.action_buffer[self.action_idx], dtype=np.float32)
                    
                    # ì²« ë²ˆì§¸ ë³´ê°„ ë‹¨ê³„ ì‹¤í–‰
                    interpolated_action = self._interpolate_action(
                        self.current_action, 
                        self.next_action, 
                        0, 
                        self.interpolation_steps
                    )
                    
                    self.interpolation_counter = 1
                    
                    # Action Smoothing ì ìš©
                    smoothed_action = self._smooth_action(interpolated_action, current_joints)
                    
                    # Velocity ì œí•œ ì ìš©
                    final_action = self._limit_velocity(smoothed_action, current_joints)
                    
                    print(f"  ğŸ¯ New action {self.action_idx}/{len(self.action_buffer)}: {final_action[:3]}...")
                    return final_action
                
                else:
                    # Action buffer ì™„ë£Œ
                    return np.array(current_joints, dtype=np.float32)
            
        except Exception as e:
            print(f"âŒ Policy inference failed: {e}")
            return np.array(obs["joint_positions"], dtype=np.float32)
    
    def _interpolate_action(self, start_action: np.ndarray, end_action: np.ndarray, step: int, total_steps: int) -> np.ndarray:
        """ë‘ action ê°„ ë¶€ë“œëŸ¬ìš´ ë³´ê°„"""
        if total_steps <= 1:
            return end_action
        
        # Linear interpolation with easing
        alpha = step / (total_steps - 1)
        
        # Easing function for smoother transition
        eased_alpha = self._ease_in_out(alpha)
        
        # ë³´ê°„ëœ action ê³„ì‚°
        interpolated = start_action + eased_alpha * (end_action - start_action)
        
        return interpolated
    
    def _ease_in_out(self, t: float) -> float:
        """ë¶€ë“œëŸ¬ìš´ easing í•¨ìˆ˜"""
        # Smooth step function
        return t * t * (3.0 - 2.0 * t)
    
    def _smooth_action(self, target_action: np.ndarray, current_joints: np.ndarray) -> np.ndarray:
        """Actionì„ ë¶€ë“œëŸ½ê²Œ í‰í™œí™”"""
        if self.last_smoothed_action is None:
            # ì²« ë²ˆì§¸ ì‹¤í–‰ ì‹œ
            self.last_smoothed_action = current_joints.copy()
        
        # Exponential smoothing ì ìš©
        # smoothed = Î± * target + (1-Î±) * last_smoothed
        smoothed = (self.smoothing_factor * target_action + 
                   (1 - self.smoothing_factor) * self.last_smoothed_action)
        
        # ê²°ê³¼ ì €ì¥
        self.last_smoothed_action = smoothed.copy()
        
        return smoothed
    
    def _limit_velocity(self, target_action: np.ndarray, current_joints: np.ndarray) -> np.ndarray:
        """Joint velocityë¥¼ ì œí•œí•˜ì—¬ ê¸‰ê²©í•œ ë³€í™” ë°©ì§€"""
        # í˜„ì¬ jointì—ì„œ targetê¹Œì§€ì˜ ë³€í™”ëŸ‰
        delta = target_action - current_joints
        
        # ìµœëŒ€ velocity ì œí•œ
        max_delta = self.max_velocity
        delta_magnitude = np.linalg.norm(delta)
        
        if delta_magnitude > max_delta:
            # Velocity ì œí•œ ì ìš©
            delta = delta / delta_magnitude * max_delta
            target_action = current_joints + delta
        
        return target_action
    
    def _request_new_actions(self, obs: dict):
        """í˜„ì¬ observationìœ¼ë¡œ ìƒˆë¡œìš´ actions ìš”ì²­"""
        try:
            print(f"  ğŸ”„ Requesting new actions with current state...")
            
            # Policy ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            formatted_obs = self._format_observation_for_policy(obs)
            
            # DEBUG: Observation ë°ì´í„° í™•ì¸
            print(f"  ğŸ“· Base image shape: {formatted_obs['observation/base_image'].shape if formatted_obs['observation/base_image'] is not None else 'None'}")
            print(f"  ğŸ“· Wrist image shape: {formatted_obs['observation/wrist_image'].shape if formatted_obs['observation/wrist_image'] is not None else 'None'}")
            print(f"  ğŸ¤– Joint positions: {formatted_obs['observation/state']}")
            
            # ğŸ¯ TASK PROMPT ìƒì„¸ í™•ì¸
            print(f"\nğŸ¯ TASK PROMPT VERIFICATION:")
            print(f"  ğŸ“ Original task prompt: '{self.task_prompt}'")
            print(f"  ğŸ“ Formatted task prompt: '{formatted_obs['prompt']}'")
            print(f"  ğŸ“ Task prompt length: {len(formatted_obs['prompt'])} characters")
            print(f"  ğŸ“ Task prompt type: {type(formatted_obs['prompt'])}")
            
            # Policy inference
            result = self.policy.infer(formatted_obs)
            
            # DEBUG: Policy ì‘ë‹µ ìƒì„¸ ë¶„ì„
            print(f"  ğŸ¯ Policy response analysis:")
            print(f"    ğŸ“‹ Response keys: {list(result.keys())}")
            
            if "actions" in result:
                actions = result["actions"]
                print(f"    ğŸ¯ Actions shape: {actions.shape if hasattr(actions, 'shape') else len(actions)}")
                print(f"    ğŸ¯ First action: {actions[0] if len(actions) > 0 else 'None'}")
                
                # ğŸš¨ Task prompt ë°˜ì˜ ì—¬ë¶€ í™•ì¸
                if "task_info" in result:
                    print(f"    ğŸ“ Task info from policy: {result['task_info']}")
                else:
                    print(f"    âš ï¸  No task_info in policy response")
                
                if "prompt_used" in result:
                    print(f"    ğŸ“ Prompt used by policy: {result['prompt_used']}")
                else:
                    print(f"    âš ï¸  No prompt_used in policy response")
                
                # Action buffer ì„¤ì •
                self.action_buffer = actions
                self.action_idx = 0
                print(f"    âœ… New actions loaded: {len(self.action_buffer)} actions")
            else:
                print("    âŒ No actions received from policy")
                print(f"    ğŸ“‹ Full response: {result}")
                
        except Exception as e:
            print(f"  âŒ Failed to request new actions: {e}")
            import traceback
            traceback.print_exc()
    
    def _format_observation_for_policy(self, obs: dict) -> dict:
        """Policyê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ observationì„ ë³€í™˜í•©ë‹ˆë‹¤"""
        # BGR â†’ RGB ë³€í™˜
        base_image = obs.get("base_rgb")
        wrist_image = obs.get("wrist_rgb")
        
        if base_image is not None:
            base_image = cv2.cvtColor(base_image, cv2.COLOR_BGR2RGB)
        if wrist_image is not None:
            wrist_image = cv2.cvtColor(wrist_image, cv2.COLOR_BGR2RGB)
        
        # ğŸ¯ UR3 Policy ì „ìš© í˜•ì‹ìœ¼ë¡œ ë³€ê²½
        # ì°¸ê³ : src/openpi/training/config.pyì˜ LeRobotUR3DataConfigì™€ ì¼ì¹˜
        formatted_obs = {
            "observation/base_image": base_image,      # base camera
            "observation/wrist_image": wrist_image,    # wrist camera
            "observation/state": obs["joint_positions"], # joint positions
            "prompt": self.task_prompt  # task prompt
        }
        
        # ğŸš¨ Task prompt ê²€ì¦
        if not self.task_prompt or len(self.task_prompt.strip()) == 0:
            print("âš ï¸  WARNING: Task prompt is empty or None!")
            print(f"  Task prompt: '{self.task_prompt}'")
            print(f"  Task prompt type: {type(self.task_prompt)}")
            print(f"  Task prompt length: {len(self.task_prompt) if self.task_prompt else 0}")
        
        # ğŸ¯ Observation ë°ì´í„° ê²€ì¦
        print(f"  ğŸ” Observation format verification (UR3):")
        print(f"    ğŸ“· Base image: {formatted_obs['observation/base_image'].shape if formatted_obs['observation/base_image'] is not None else 'None'}")
        print(f"    ğŸ“· Wrist image: {formatted_obs['observation/wrist_image'].shape if formatted_obs['observation/wrist_image'] is not None else 'None'}")
        print(f"    ğŸ¤– Joint positions: {formatted_obs['observation/state']}")
        print(f"    ğŸ“ Task prompt: '{formatted_obs['prompt']}'")
        
        return formatted_obs


def main(args):
    if not GELLO_AVAILABLE:
        print("âŒ Gello libraries are required")
        return
    
    if args.agent == "policy" and not OPENPI_AVAILABLE:
        print("âŒ OpenPI client is required for policy agent")
        return
    
    # ë¡œë´‡ê³¼ ì¹´ë©”ë¼ ì´ˆê¸°í™”
    if args.mock:
        robot_client = PrintRobot(8, dont_print=True)
        camera_clients = {}
    else:
        # RealSense ì¹´ë©”ë¼ ì´ˆê¸°í™”
        ctx = rs.context()
        devs = ctx.query_devices()
        if len(devs) < 2:
            print("âŒ ë‘ ëŒ€ ì´ìƒì˜ RealSenseê°€ ì—°ê²°ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return
        
        serials = [dev.get_info(rs.camera_info.serial_number) for dev in devs[:2]]
        drivers = [RealSenseDriver(s, args.camera_width, args.camera_height, args.camera_fps) 
                  for s in serials]
        
        # ì¹´ë©”ë¼ ì„œë²„ ì‹œì‘
        ports = [args.wrist_camera_port, args.base_camera_port]
        threads = []
        for port, drv in zip(ports, drivers):
            t = threading.Thread(target=start_server, args=(port, drv), daemon=True)
            t.start()
            threads.append(t)

        time.sleep(1)  # ë°”ì¸ë”© ëŒ€ê¸°

        # ì¹´ë©”ë¼ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
        client1 = ZMQClientCamera(port=args.wrist_camera_port)
        client2 = ZMQClientCamera(port=args.base_camera_port)
        
        camera_clients = {
            "wrist": AsyncCamera(client1, crop_center=(320, 240)),
            "base": AsyncCamera(client2),
        }
        
        # DEBUG: ì¹´ë©”ë¼ ì—°ê²° ìƒíƒœ í™•ì¸
        print("\nğŸ“· DEBUG: Camera Status")
        print(f"  ğŸ“· Wrist camera port: {args.wrist_camera_port}")
        print(f"  ğŸ“· Base camera port: {args.base_camera_port}")
        print(f"  ğŸ“· Camera clients: {list(camera_clients.keys())}")
        
        # ì¹´ë©”ë¼ í”„ë ˆì„ í…ŒìŠ¤íŠ¸
        time.sleep(2)  # ì¹´ë©”ë¼ ì´ˆê¸°í™” ëŒ€ê¸°
        for cam_name, cam in camera_clients.items():
            frame = cam.read()
            if frame is not None:
                print(f"  âœ… {cam_name} camera: frame shape {frame.shape}, dtype {frame.dtype}")
            else:
                print(f"  âŒ {cam_name} camera: no frame received")
        
        # ë¡œë´‡ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
        robot_client = ZMQClientRobot(port=args.robot_port, host=args.hostname)
    
    # Gello í™˜ê²½ ìƒì„±
    env = RobotEnv(robot_client, control_rate_hz=args.hz, camera_dict=camera_clients)
    
    # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    if args.agent == "policy":
        print(f"\nğŸ¯ POLICY AGENT INITIALIZATION:")
        print(f"  ğŸ“ Task prompt: '{args.task_prompt}'")
        print(f"  ğŸ“ Task prompt length: {len(args.task_prompt)} characters")
        print(f"  ğŸ“ Task prompt type: {type(args.task_prompt)}")
        print(f"  ğŸ“ Policy host: {args.policy_host}:{args.policy_port}")
        
        # ğŸš¨ Task prompt ê²€ì¦
        if not args.task_prompt or len(args.task_prompt.strip()) == 0:
            print("  âŒ ERROR: Task prompt is empty or None!")
            print("  âŒ This will cause the policy to ignore task instructions!")
            return
        elif len(args.task_prompt.strip()) < 10:
            print("  âš ï¸  WARNING: Task prompt seems too short!")
            print("  âš ï¸  Consider using a more descriptive task description")
        
        # Task promptê°€ ê¸°ë³¸ê°’ì¸ì§€ í™•ì¸
        default_prompt = "pick up the green grape and put it in the gray pot"
        if args.task_prompt == default_prompt:
            print("  âš ï¸  WARNING: Using default task prompt!")
            print("  âš ï¸  Consider specifying a custom task with --task-prompt")
        
        agent = PolicyAgent(args.policy_host, args.policy_port, args.api_key, args.task_prompt, args.open_loop_horizon)
        # Smoothing íŒŒë¼ë¯¸í„° ì„¤ì •
        agent.smoothing_factor = args.smoothing_factor
        agent.max_velocity = args.max_action_velocity
        # Interpolation íŒŒë¼ë¯¸í„° ì„¤ì •
        agent.interpolation_steps = args.interpolation_steps
    elif args.agent == "gello":
        gello_port = args.gello_port
        if gello_port is None:
            usb_ports = glob.glob("/dev/serial/by-id/*")
            print(f"Found {len(usb_ports)} ports")
            if len(usb_ports) > 0:
                gello_port = usb_ports[0]
                print(f"using port {gello_port}")
            else:
                raise ValueError("No gello port found, please specify one or plug in gello")
        
        if args.start_joints is None:
            reset_joints = np.deg2rad([0, -90, -90, -90, 90, 180])
        else:
            reset_joints = args.start_joints
        
        agent = GelloAgent(port=gello_port, start_joints=args.start_joints)
        
        # ì´ˆê¸° ìœ„ì¹˜ë¡œ ì´ë™
        curr_joints = env.get_obs()["joint_positions"]
        if reset_joints.shape == curr_joints.shape:
            max_delta = (np.abs(curr_joints - reset_joints)).max()
            steps = min(int(max_delta / 0.01), 100)
            for jnt in np.linspace(curr_joints, reset_joints, steps):
                env.step(jnt)
                time.sleep(0.001)
    
    elif args.agent == "dummy" or args.agent == "none":
        agent = DummyAgent(num_dofs=robot_client.num_dofs())
    else:
        raise ValueError(f"Invalid agent name: {args.agent}")
    
    # ì‹œì‘ ìœ„ì¹˜ë¡œ ì´ë™
    print("Going to start position")
    start_pos = agent.act(env.get_obs())
    obs = env.get_obs()
    joints = obs["joint_positions"]

    abs_deltas = np.abs(start_pos - joints)
    id_max_joint_delta = np.argmax(abs_deltas)

    if abs_deltas[id_max_joint_delta] > args.max_joint_delta:
        id_mask = abs_deltas > args.max_joint_delta
        print()
        ids = np.arange(len(id_mask))[id_mask]
        for i, delta, joint, current_j in zip(
            ids,
            abs_deltas[id_mask],
            start_pos[id_mask],
            joints[id_mask],
        ):
            print(f"joint[{i}]: \t delta: {delta:4.3f} , leader: \t{joint:4.3f} , follower: \t{current_j:4.3f}")
        return

    print(f"Start pos: {len(start_pos)}", f"Joints: {len(joints)}")
    assert len(start_pos) == len(joints), f"agent output dim = {len(start_pos)}, but env dim = {len(joints)}"

    # ë¶€ë“œëŸ¬ìš´ ì‹œì‘ì„ ìœ„í•œ ì ì§„ì  ì´ë™
    max_delta = 0.05
    for _ in range(25):
        obs = env.get_obs()
        command_joints = agent.act(obs)
        current_joints = obs["joint_positions"]
        delta = command_joints - current_joints
        max_joint_delta = np.abs(delta).max()
        if max_joint_delta > max_delta:
            delta = delta / max_joint_delta * max_delta
        env.step(current_joints + delta)

    # ìµœì¢… ìœ„ì¹˜ í™•ì¸
    obs = env.get_obs()
    joints = obs["joint_positions"]
    action = agent.act(obs)
    if (action - joints > 0.5).any():
        print("Action is too big")
        joint_index = np.where(action - joints > 0.8)
        for j in joint_index:
            print(f"Joint [{j}], leader: {action[j]}, follower: {joints[j]}, diff: {action[j] - joints[j]}")
        exit()

    # í‚¤ë³´ë“œ ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”
    if args.use_save_interface:
        from gello.data_utils.keyboard_interface import KBReset
        kb_interface = KBReset()

    print_color("\nStart ğŸš€ğŸš€ğŸš€", color="green", attrs=("bold",))

    # ë©”ì¸ ì œì–´ ë£¨í”„
    save_path = None
    buffer: List[Tuple[Dict[str, Any], np.ndarray]] = []
    recording: bool = False
    start_time = time.time()
    
    while True:
        # ì‹œê°„ í‘œì‹œ
        num = time.time() - start_time
        message = f"\rTime passed: {round(num, 2)}          "
        print_color(message, color="white", attrs=("bold",), end="", flush=True)
        
        # ì—ì´ì „íŠ¸ë¡œë¶€í„° action ê°€ì ¸ì˜¤ê¸°
        action = agent.act(obs)
        
        # DEBUG: ì£¼ê¸°ì  observation ìƒíƒœ í™•ì¸ (10ì´ˆë§ˆë‹¤)
        if int(time.time() - start_time) % 10 == 0:
            print(f"\nğŸ” DEBUG: Current Observation Status (t={int(time.time() - start_time)}s)")
            print(f"  ğŸ“· Base RGB available: {'base_rgb' in obs}")
            print(f"  ğŸ“· Wrist RGB available: {'wrist_rgb' in obs}")
            print(f"  ğŸ¤– Joint positions available: {'joint_positions' in obs}")
            if 'joint_positions' in obs:
                print(f"  ğŸ¤– Current joints: {obs['joint_positions']}")
            if 'base_rgb' in obs and obs['base_rgb'] is not None:
                print(f"  ğŸ“· Base image: {obs['base_rgb'].shape}, dtype: {obs['base_rgb'].dtype}")
            if 'wrist_rgb' in obs and obs['wrist_rgb'] is not None:
                print(f"  ğŸ“· Wrist image: {obs['wrist_rgb'].shape}, dtype: {obs['wrist_rgb'].dtype}")
        
        # ë°ì´í„° ì €ì¥ ì¸í„°í˜ì´ìŠ¤
        if args.use_save_interface:
            state = kb_interface.update()
            if state == "start":
                dt_time = datetime.datetime.now()
                save_path = (
                    Path(args.data_dir).expanduser()
                    / args.agent
                    / dt_time.strftime("%m%d_%H%M%S")
                )
                save_path.mkdir(parents=True, exist_ok=True)
                print(f"Recording to {save_path}")
                buffer.clear()
                recording = True

            elif state == "save":
                assert save_path is not None, "something went wrong"
                buffer.append((obs.copy(), action.copy()))  

            elif state == "normal":
                if recording:
                    # End of recording: flush buffer to HDF5
                    if save_path and buffer:
                        # Create HDF5 file
                        h5_file = save_path / "data.hdf5"
                        with h5py.File(h5_file, 'w') as f:
                            grp = f.create_group('data')
                            # keys from first obs
                            keys = list(buffer[0][0].keys())
                            # prepare arrays
                            for key in keys:
                                # stack obs values
                                data_arr = np.stack([b[0][key] for b in buffer], axis=0)
                                grp.create_dataset(key, data=data_arr)
                            # actions
                            acts = np.stack([b[1] for b in buffer], axis=0)
                            grp.create_dataset('actions', data=acts)
                        
                        # ë™ì¼ í´ë”ì— RGB ë¹„ë””ì˜¤ë¡œë„ ì €ì¥
                        fps = 30
                        fourcc = cv2.VideoWriter_fourcc(*'mp4v')

                        # base ì™€ wrist ê° ì¹´ë©”ë¼ë³„ë¡œ ë¹„ë””ì˜¤ ìƒì„±
                        for cam in ('base', 'wrist'):
                            frames = [b[0][f'{cam}_rgb'] for b in buffer]
                            h, w = frames[0].shape[:2]
                            video_path = save_path / f"{cam}_rgb.mp4"
                            vw = cv2.VideoWriter(str(video_path), fourcc, fps, (w, h))
                            for frame in frames:
                                vw.write(frame)
                            vw.release()
                    
                    # reset
                    recording = False
                    buffer.clear()
                    save_path = None
            else:
                raise ValueError(f"Invalid state {state}")
        
        # Action ì‹¤í–‰
        print("start")
        t0 = time.perf_counter()
        obs = env.step(action)
        
        # ê³ ì • ì£¼ê¸° ì œì–´ (ì´ì „ ë°©ì‹ìœ¼ë¡œ ë³µì›)
        dt_actual = time.perf_counter() - t0
        dt_target = 1.0 / args.hz
        
        # ì œì–´ ì£¼íŒŒìˆ˜ ë§ì¶”ê¸°
        sleep_time = dt_target - dt_actual
        if sleep_time > 0:
            time.sleep(sleep_time)
            total_time = time.perf_counter() - t0
            print(f"[Timing] env.step(): {dt_actual*1000:.1f}ms + sleep: {sleep_time*1000:.1f}ms = ì´ {total_time*1000:.1f}ms (ëª©í‘œ: {dt_target*1000:.1f}ms)")
        else:
            print(f"[Warning] âš ï¸  ì²˜ë¦¬ ì‹œê°„ì´ {dt_actual*1000:.1f}msë¡œ ëª©í‘œ ì£¼ê¸° {dt_target*1000:.1f}msë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")

        print("end")


if __name__ == "__main__":
    main(tyro.cli(Args))